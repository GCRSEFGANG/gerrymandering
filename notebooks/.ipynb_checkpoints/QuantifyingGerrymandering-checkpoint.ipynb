{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying Gerrymandering\n",
    "\n",
    "## Existing Methods\n",
    "\n",
    "The two main attempts to quantify gerrymandering so far have been:\n",
    "\n",
    "### 1) The Efficiency Gap\n",
    "\n",
    "The efficiency gap measures the *wasted vote* of each of party.\n",
    "\n",
    "The wasted vote is the number of votes that did not go towards the winning candidate. This means votes for the losing candidate, and votes casted for the winning candidate after they had already gotten a majority.\n",
    "\n",
    "The efficiency gap takes the difference between the number of wasted votes for each party, and divides that by the number of votes casted in total.\n",
    "\n",
    "It is not a reliable method of measuring gerrymandering as it often falsely identifies or completely misses gerrymandering.\n",
    "\n",
    "In 2014, roughly the same number of people voted for Democrats and Republicans in Illinois, but Democrats ended up winning 71-47 in the state house, even though the efficiency gap was only 2.3%.\n",
    "\n",
    "### 2) Supercomputing\n",
    "\n",
    "Researchers from the University of Illinois have used a supercomputer to generate billions of unbiased maps, and compared them to current districts to see if they were similar. Their method is unique and effective, but computationally expensive.\n",
    "\n",
    "## Our Method\n",
    "\n",
    "Our method of measuring gerrymandering begins at its root. Gerrymandering is cracking and packing political communities, so why not find those communities? Our algorithm to do so is an implementation of the iterative method, with constraints of partisanship diversity (grouping like-minded people), compactness, and population.\n",
    "\n",
    "We then take these communities and compare them to the current districts. The gerrymandering score for a district is the percentage of the district that is not occupied by the community that occupies the largest area in that district."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we've already generated the base communities and they are stored in `data/nh_base_communities.pickle`.\n",
    "Here's what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community 1\n",
      "Iteration\tPartisanship\tDiversity\tCompactness\tPopulation\n",
      "1\t\t0.449\t\t10.543\t\t0.438\t\t301672\n",
      "2\t\t0.451\t\t10.226\t\t0.408\t\t433037\n",
      "3\t\t0.451\t\t10.482\t\t0.339\t\t433578\n",
      "4\t\t0.426\t\t10.27\t\t0.356\t\t472926\n",
      "5\t\t0.426\t\t10.264\t\t0.368\t\t473968\n",
      "\n",
      "Community 2\n",
      "Iteration\tPartisanship\tDiversity\tCompactness\tPopulation\n",
      "1\t\t0.487\t\t10.308\t\t0.303\t\t714549.0\n",
      "2\t\t0.495\t\t10.19\t\t0.225\t\t583184.0\n",
      "3\t\t0.494\t\t9.793\t\t0.225\t\t582643.0\n",
      "4\t\t0.516\t\t8.121\t\t0.302\t\t543295.0\n",
      "5\t\t0.516\t\t8.155\t\t0.312\t\t542253.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from hacking_the_election.utils.community import Community\n",
    "from hacking_the_election.serialization.save_precincts import Precinct\n",
    "\n",
    "\n",
    "with open(\"data/nh_base_communities.pickle\", \"rb\") as f:\n",
    "    community_stages, changed_precincts = pickle.load(f)\n",
    "\n",
    "# Sort the communities in each stage by id.\n",
    "for stage in community_stages:\n",
    "    stage.sort(key=lambda c: c.id)\n",
    "\n",
    "# Update each of the relevant attributes of each of the community objects.\n",
    "for stage in community_stages:\n",
    "    for community in stage:\n",
    "        community.update_partisanship()\n",
    "        community.update_standard_deviation()\n",
    "        community.update_compactness()\n",
    "        community.update_population()\n",
    "\n",
    "# Print the data.\n",
    "for i in range(len(community_stages[0])):\n",
    "    print(f\"Community {community_stages[0][i].id}\")\n",
    "    print(\"Iteration\\tPartisanship\\tDiversity\\tCompactness\\tPopulation\")\n",
    "    for s, stage in enumerate(community_stages):\n",
    "        print(\"\\t\\t\".join([] \\\n",
    "            + [str(round(i, 3)) for i in [\n",
    "                s + 1,\n",
    "                stage[i].partisanship,\n",
    "                stage[i].standard_deviation,\n",
    "                stage[i].compactness,\n",
    "                stage[i].population]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how each of the constraints changed over the iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_squishing_function(min_val, max_val):\n",
    "    \"\"\"\n",
    "    Returns a function that takes an input between `min_val` and `max_val` and\n",
    "    returns a proportionate value between 0 and 1.\n",
    "    \"\"\"\n",
    "    def squish(x):\n",
    "        return (x - max_val) / (max_val - min_val)\n",
    "    return squish\n",
    "\n",
    "\n",
    "# Constraint values for each iteration:\n",
    "average_pop = sum([c.population for c in community_stages[0]]) / 2\n",
    "average_constraints = [\n",
    "    [sum([c.standard_deviation for c in stage]) / (l := len(stage)),\n",
    "     sum([1 - c.compactness for c in stage]) / l,\n",
    "     sum([(abs(c.population - average_pop) / average_pop) * 100\n",
    "          for c in stage]) / l]\n",
    "    for stage in community_stages\n",
    "]\n",
    "\n",
    "# Create squishing functions for each constraint:\n",
    "stdev_squish = get_squishing_function(\n",
    "    min([stage[0] for stage in average_constraints]),\n",
    "    max([stage[0] for stage in average_constraints])\n",
    ")\n",
    "compactness_squish = get_squishing_function(\n",
    "    min([stage[1] for stage in average_constraints]),\n",
    "    max([stage[1] for stage in average_constraints])\n",
    ")\n",
    "population_squish = get_squishing_function(\n",
    "    min([stage[2] for stage in average_constraints]),\n",
    "    max([stage[2] for stage in average_constraints])\n",
    ")\n",
    "\n",
    "X = list(range(len(community_stages)))\n",
    "Y = [[] for _ in community_stages]\n",
    "for iteration in average_constraints:\n",
    "    Y[0].append(stdev_squish(iteration[0]))\n",
    "    Y[1].append(compactness_squish(iteration[1]))\n",
    "    Y[2].append(population_squish(iteration[2]))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Average Constraint Values Over Iterations\")\n",
    "constraint_order = [\n",
    "    \"Partisanship Diversity\",\n",
    "    \"Uncompactness\",\n",
    "    \"Difference in Population from Average\"\n",
    "]\n",
    "for constraint_name, constraint_line in zip(constraint_order, Y):\n",
    "    line, = ax.plot(X, constraint_line)\n",
    "    line.set_label(constraint_name)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38064bitvenvvenv694e31346179489bbbab81ea1a2d244f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
